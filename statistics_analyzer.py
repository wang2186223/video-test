#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹ç»Ÿè®¡åˆ†æè„šæœ¬
ç”¨äºåˆ†æè®¿é—®æ—¥å¿—CSVæ–‡ä»¶ï¼Œç”Ÿæˆç»Ÿè®¡æ±‡æ€»è¡¨

ä½¿ç”¨æ–¹æ³•:
python statistics_analyzer.py <csvæ–‡ä»¶è·¯å¾„>

ç¤ºä¾‹:
python statistics_analyzer.py "ads-recan - è¯¦ç»†-2025-10-11.csv"
"""

import csv
import sys
import os
from urllib.parse import urlparse
from datetime import datetime
from collections import defaultdict
import argparse

def parse_page_url(url):
    """
    è§£æé¡µé¢URLï¼Œæå–åŸŸåå’Œä¹¦ç±ä¿¡æ¯
    è¿”å›: (åŸŸå, ä¹¦ç±åç§°, æ˜¯å¦ä¸ºç« èŠ‚é¡µé¢)
    """
    try:
        parsed = urlparse(url)
        domain = parsed.netloc
        path = parsed.path
        
        # æå–ä¹¦ç±åç§°
        if '/novels/' in path:
            # åŒ¹é… /novels/ä¹¦ç±åç§°/chapter-æ•°å­— æˆ– /novels/ä¹¦ç±åç§°
            parts = path.split('/novels/')
            if len(parts) > 1:
                book_path = parts[1].split('/')[0]
                # ç§»é™¤URLå‚æ•°
                book_name = book_path.split('?')[0]
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºç« èŠ‚é¡µé¢
                is_chapter = '/chapter-' in path
                
                return domain, book_name, is_chapter
    except Exception as e:
        print(f"URLè§£æé”™è¯¯: {url}, é”™è¯¯: {e}")
        return None, None, False
    
    return None, None, False

def format_book_name(book_name):
    """
    æ ¼å¼åŒ–ä¹¦ç±åç§°ï¼Œè½¬æ¢ä¸ºæ›´å¯è¯»çš„æ ¼å¼
    """
    if not book_name:
        return "æœªçŸ¥ä¹¦ç±"
    
    # æ›¿æ¢è¿å­—ç¬¦ä¸ºç©ºæ ¼ï¼Œå¹¶è¿›è¡Œæ ‡é¢˜åŒ–
    formatted = book_name.replace('-', ' ').title()
    
    # ç‰¹æ®Šå¤„ç†ä¸€äº›å¸¸è§çš„ä¹¦åæ ¼å¼
    replacements = {
        'Ceo': 'CEO',
        'Billionaire': 'Billionaire',
        'Heartbreak Billionairehe': 'Heartbreak Billionaire: He'
    }
    
    for old, new in replacements.items():
        formatted = formatted.replace(old, new)
    
    return formatted

def analyze_csv_file(csv_file_path):
    """
    åˆ†æCSVæ–‡ä»¶ï¼Œç”Ÿæˆç»Ÿè®¡æ•°æ®
    """
    print(f"æ­£åœ¨åˆ†ææ–‡ä»¶: {csv_file_path}")
    
    if not os.path.exists(csv_file_path):
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {csv_file_path}")
        return None
    
    # ç»Ÿè®¡æ•°æ®ç»“æ„: {(åŸŸå, ä¹¦ç±åç§°): {"chapters": set(), "ips": set()}}
    stats = defaultdict(lambda: {"chapters": set(), "ips": set(), "total_visits": 0})
    
    total_rows = 0
    valid_rows = 0
    
    try:
        with open(csv_file_path, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            
            # éªŒè¯CSVåˆ—å
            expected_columns = ['æ—¶é—´', 'è®¿é—®é¡µé¢', 'ç”¨æˆ·å±æ€§', 'æ¥æºé¡µé¢', 'ip']
            if not all(col in reader.fieldnames for col in expected_columns):
                print(f"é”™è¯¯: CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—ã€‚æœŸæœ›: {expected_columns}, å®é™…: {reader.fieldnames}")
                return None
            
            for row in reader:
                total_rows += 1
                
                page_url = row.get('è®¿é—®é¡µé¢', '').strip()
                ip_address = row.get('ip', '').strip()
                
                if not page_url:
                    continue
                
                # è§£æURL
                domain, book_name, is_chapter = parse_page_url(page_url)
                
                if domain and book_name:
                    valid_rows += 1
                    key = (domain, book_name)
                    
                    # ç»Ÿè®¡æ€»è®¿é—®æ¬¡æ•°
                    stats[key]["total_visits"] += 1
                    
                    # å¦‚æœæ˜¯ç« èŠ‚é¡µé¢ï¼Œè®°å½•ç« èŠ‚
                    if is_chapter:
                        stats[key]["chapters"].add(page_url)
                    
                    # è®°å½•IPåœ°å€ï¼ˆå»é‡ï¼‰
                    if ip_address and ip_address.lower() not in ['', 'unknown', 'error']:
                        stats[key]["ips"].add(ip_address)
    
    except Exception as e:
        print(f"è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None
    
    print(f"æ€»è¡Œæ•°: {total_rows}, æœ‰æ•ˆè¡Œæ•°: {valid_rows}")
    return stats

def generate_statistics_table(stats, date_str):
    """
    ç”Ÿæˆç»Ÿè®¡æ±‡æ€»è¡¨
    """
    if not stats:
        print("æ²¡æœ‰æ•°æ®å¯ä»¥ç»Ÿè®¡")
        return []
    
    result = []
    
    # æŒ‰ä¹¦ç±åç§°æ’åº
    sorted_stats = sorted(stats.items(), key=lambda x: x[0][1])
    
    for (domain, book_name), data in sorted_stats:
        formatted_book_name = format_book_name(book_name)
        chapter_count = len(data["chapters"])
        ip_count = len(data["ips"])
        total_visits = data["total_visits"]
        
        result.append([
            date_str,           # æ—¶é—´
            domain,             # åŸŸåæ¥æº
            formatted_book_name, # ä¹¦ç±åç§°
            chapter_count,      # ç´¯è®¡ç« èŠ‚ï¼ˆå«chapterçš„urlï¼‰
            ip_count,           # ç´¯è®¡ipæ•°é‡ï¼ˆå»é‡ï¼‰
            total_visits        # æ€»è®¿é—®æ¬¡æ•°ï¼ˆé¢å¤–ä¿¡æ¯ï¼‰
        ])
    
    return result

def save_statistics_to_csv(statistics, output_file):
    """
    ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°CSVæ–‡ä»¶
    """
    headers = ['æ—¶é—´', 'åŸŸåæ¥æºï¼ˆä¸è®°å½•åç¼€ï¼‰', 'ä¹¦ç±åç§°', 'ç´¯è®¡ç« èŠ‚ï¼ˆå«chapterçš„urlï¼‰', 'ç´¯è®¡ipæ•°é‡ï¼ˆå»é‡ï¼‰', 'æ€»è®¿é—®æ¬¡æ•°']
    
    try:
        with open(output_file, 'w', encoding='utf-8', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(headers)
            writer.writerows(statistics)
        
        print(f"ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        return True
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def print_statistics(statistics):
    """
    åœ¨æ§åˆ¶å°æ‰“å°ç»Ÿè®¡ç»“æœ
    """
    if not statistics:
        print("æ²¡æœ‰ç»Ÿè®¡æ•°æ®")
        return
    
    print("\n" + "="*100)
    print("ğŸ“Š è®¿é—®ç»Ÿè®¡æ±‡æ€»è¡¨")
    print("="*100)
    
    # æ‰“å°è¡¨å¤´
    print(f"{'æ—¶é—´':<12} {'åŸŸåæ¥æº':<25} {'ä¹¦ç±åç§°':<35} {'ç« èŠ‚æ•°':<8} {'IPæ•°é‡':<8} {'æ€»è®¿é—®':<8}")
    print("-"*100)
    
    # æ‰“å°æ•°æ®
    total_chapters = 0
    total_ips = 0
    total_visits = 0
    
    for row in statistics:
        date_str, domain, book_name, chapter_count, ip_count, visit_count = row
        print(f"{date_str:<12} {domain:<25} {book_name:<35} {chapter_count:<8} {ip_count:<8} {visit_count:<8}")
        total_chapters += chapter_count
        total_ips += ip_count
        total_visits += visit_count
    
    print("-"*100)
    print(f"{'æ€»è®¡':<72} {total_chapters:<8} {total_ips:<8} {total_visits:<8}")
    print("="*100)

def extract_date_from_filename(filename):
    """
    ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸ
    """
    # åŒ¹é…æ–‡ä»¶åä¸­çš„æ—¥æœŸæ ¼å¼ï¼šYYYY-MM-DD
    import re
    match = re.search(r'(\d{4}-\d{2}-\d{2})', filename)
    if match:
        date_str = match.group(1)
        try:
            # è½¬æ¢ä¸ºä¸­æ–‡æ—¥æœŸæ ¼å¼
            date_obj = datetime.strptime(date_str, '%Y-%m-%d')
            return f"{date_obj.month}æœˆ{date_obj.day}æ—¥"
        except:
            return date_str
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
    return datetime.now().strftime("%mæœˆ%dæ—¥")

def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description='åˆ†æè®¿é—®æ—¥å¿—CSVæ–‡ä»¶ç”Ÿæˆç»Ÿè®¡æŠ¥è¡¨')
    parser.add_argument('csv_file', help='CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('-q', '--quiet', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºè¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    csv_file_path = args.csv_file
    
    # åˆ†æCSVæ–‡ä»¶
    stats = analyze_csv_file(csv_file_path)
    if not stats:
        print("åˆ†æå¤±è´¥æˆ–æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return 1
    
    # æå–æ—¥æœŸ
    date_str = extract_date_from_filename(os.path.basename(csv_file_path))
    
    # ç”Ÿæˆç»Ÿè®¡è¡¨
    statistics = generate_statistics_table(stats, date_str)
    
    # æ˜¾ç¤ºç»“æœ
    if not args.quiet:
        print_statistics(statistics)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    if args.output:
        output_file = args.output
    else:
        # é»˜è®¤è¾“å‡ºæ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(csv_file_path))[0]
        output_file = f"ç»Ÿè®¡æ±‡æ€»-{base_name}.csv"
    
    if save_statistics_to_csv(statistics, output_file):
        print(f"\nâœ… ç»Ÿè®¡å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {output_file}")
        return 0
    else:
        print("\nâŒ ä¿å­˜æ–‡ä»¶å¤±è´¥")
        return 1

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print(f"python {sys.argv[0]} <CSVæ–‡ä»¶è·¯å¾„> [-o è¾“å‡ºæ–‡ä»¶è·¯å¾„] [-q]")
        print("\nç¤ºä¾‹:")
        print(f'python {sys.argv[0]} "ads-recan - è¯¦ç»†-2025-10-11.csv"')
        print(f'python {sys.argv[0]} "ads-recan - è¯¦ç»†-2025-10-11.csv" -o "ç»Ÿè®¡ç»“æœ.csv"')
        sys.exit(1)
    
    sys.exit(main())